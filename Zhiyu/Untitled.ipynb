{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c69f02-43d9-43f5-b547-becef2f6848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import joblib  # for loading the saved model\n",
    "import pickle\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Set the title of the web app\n",
    "st.title(\"Welcome to LEARN-MATCH System !\")\n",
    "\n",
    "# Input for course topic (a text field)\n",
    "topic = st.text_input(\"Enter the your interested topic (e.g., Python Programming):\")\n",
    "\n",
    "# Difficulty level selection (radio buttons)\n",
    "difficulty = st.radio(\n",
    "    \"Select difficulty level:\",\n",
    "    (\"All Levels\", \"Beginner\", \"Intermediate\", \"Expert\")\n",
    ")\n",
    "\n",
    "# Language selection (selectbox)\n",
    "language = st.selectbox(\n",
    "    \"Select the course language:\",\n",
    "    (\"English\", \"Spanish\", \"French\", \"German\", \"Chinese\")\n",
    ")\n",
    "\n",
    "# Credit eligibility (radio buttons)\n",
    "credit_eligibility = st.radio(\n",
    "    \"Are you eligible for credits?\",\n",
    "    (\"Yes\", \"No\")\n",
    ")\n",
    "\n",
    "# Submit button\n",
    "if st.button(\"Submit\"):\n",
    "    # When the button is clicked, display the selected options\n",
    "    st.write(\"You selected the following options:\")\n",
    "    st.write(f\"Topic: {topic}\")\n",
    "    st.write(f\"Difficulty Level: {difficulty}\")\n",
    "    st.write(f\"Language: {language}\")\n",
    "    st.write(f\"Credit Eligibility: {credit_eligibility}\")\n",
    "# Create a dictionary with the user input\n",
    "    user_input = {\n",
    "        \"title\": [topic],\n",
    "        \"level\": [difficulty],\n",
    "        \"language\": [language],\n",
    "        \"crediteligibility\": [credit_eligibility]\n",
    "    }\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    df_input = pd.DataFrame(user_input)\n",
    "    df_input = pd.DataFrame(user_input)\n",
    "\n",
    "    # Check if the CSV file exists, and append data\n",
    "    if os.path.isfile(\"input.csv\"):\n",
    "        df_existing = pd.read_csv(\"input.csv\")\n",
    "        df_combined = pd.concat([df_existing, df_input], ignore_index=True)\n",
    "        df_combined.to_csv(\"input.csv\", index=False)\n",
    "    else:\n",
    "        df_input.to_csv(\"input.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297317dc-8891-42a9-83cf-1de431da3c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.title(\"We are customizing the course for you ......\")\n",
    "# Step 1: Load the CSV file\n",
    "if 'input.csv' in st.session_state:\n",
    "    df_basic = pd.read_csv('input.csv')\n",
    "    st.write(\"Data Loaded Successfully:\")\n",
    "    st.dataframe(df_basic)\n",
    "\n",
    "    # Step 2: Preprocess titles (convert to lowercase)\n",
    "    df_basic['processed_title'] = df_basic['title'].str.lower()\n",
    "\n",
    "    # Step 3: Apply TfidfVectorizer to convert text to numerical form\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    X = vectorizer.fit_transform(df_basic['processed_title'])\n",
    "\n",
    "    # Step 4: Calculate cosine similarity matrix\n",
    "    cosine_sim = cosine_similarity(X, X)\n",
    "\n",
    "    # Step 5: Use clustering or thresholding to group similar titles\n",
    "    threshold = 0.5  # Define similarity threshold to consider titles similar\n",
    "    unique_ids = []\n",
    "    for i in range(len(cosine_sim)):\n",
    "        found = False\n",
    "        for uid in unique_ids:\n",
    "            if cosine_sim[i, uid] > threshold:\n",
    "                unique_ids.append(uid)\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            unique_ids.append(i)\n",
    "\n",
    "    # Step 6: Add unique_ids as a column to the dataframe\n",
    "    df_basic['unique_title'] = unique_ids\n",
    "\n",
    "    # Step 7: Apply Label Encoding to categorical columns\n",
    "    le = LabelEncoder()\n",
    "    df_basic['level_encoded'] = le.fit_transform(df_basic['level'])\n",
    "    df_basic['language_encoded'] = le.fit_transform(df_basic['language'])\n",
    "    df_basic['credit_eligibility_encoded'] = le.fit_transform(df_basic['credit_eligibility'])\n",
    "\n",
    "    # Display the processed DataFrame\n",
    "    #st.write(\"Processed Data with Similar Titles Grouped and Encoded Levels:\")\n",
    "    #st.dataframe(df_basic[['title', 'unique_title', 'level_encoded', 'language_encoded', 'credit_eligibility_encoded']])\n",
    "\n",
    "    # Optionally save the processed DataFrame\n",
    "    #if st.button(\"Save Processed Data\"):\n",
    "    df_basic.to_csv(\"processed_input.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed4f448-7438-4a1a-9e1f-20ca9cfbabe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # load the save model and perform K-means clustering\n",
    "    uploaded_file = \"processed_input.csv\"\n",
    "    if uploaded_file:\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "        #st.write(\"Processed data loaded:\")\n",
    "        #st.dataframe(df)\n",
    "    \n",
    "        # Step 2: Load the saved KMeans model\n",
    "        model_file = 'kmeans_optimal_basic.pkl'  # replace with your actual saved pickle file\n",
    "    \n",
    "        with open(model_file, 'rb') as file:\n",
    "            kmeans = pickle.load(file)\n",
    "            #st.write(\"KMeans model loaded successfully.\")\n",
    "    \n",
    "            # Step 3: Perform clustering using the loaded model\n",
    "            # Exclude non-numeric columns (assuming only numerical features are relevant for clustering)\n",
    "        numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "        X = df[numeric_columns]\n",
    "    \n",
    "            # Predict cluster labels\n",
    "        df['cluster'] = kmeans.predict(X)\n",
    "    \n",
    "        input_data_point = X.iloc[[0]]  # Replace with actual user-input data point if available\n",
    "        input_cluster = df['cluster'].iloc[0]\n",
    "    \n",
    "        # Filter only the data points within the same cluster as the input\n",
    "        cluster_points = X[df['cluster'] == input_cluster]\n",
    "    \n",
    "        # Calculate distances to the input data point\n",
    "        _, distances = pairwise_distances_argmin_min(input_data_point, cluster_points)\n",
    "    \n",
    "        # Get the indices of the top 3 closest points\n",
    "        closest_indices = np.argsort(distances)[:3]\n",
    "        closest_courses = cluster_points.iloc[closest_indices]\n",
    "    \n",
    "        st.write(\"Top 3 course recomended for you:\")\n",
    "        st.dataframe(df.loc[closest_courses.index, ['title'] + list(numeric_columns)])\n",
    "                                                                                          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
